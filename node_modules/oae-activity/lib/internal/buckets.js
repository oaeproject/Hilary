/*!
 * Copyright 2014 Apereo Foundation (AF) Licensed under the
 * Educational Community License, Version 2.0 (the "License"); you may
 * not use this file except in compliance with the License. You may
 * obtain a copy of the License at
 *
 *     http://opensource.org/licenses/ECL-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an "AS IS"
 * BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 * or implied. See the License for the specific language governing
 * permissions and limitations under the License.
 */

var _ = require('underscore');
var crypto = require('crypto');
var util = require('util');

var Locking = require('oae-util/lib/locking');
var log = require('oae-logger').logger('oae-activity-buckets');
var OAE = require('oae-util/lib/oae');
var TelemetryAPI = require('oae-telemetry');

var ActivitySystemConfig = require('./config');

// Holds the current amount of buckets that are being collected and telemtry object per type of bucket
var bucketsInfo = {};

// Whether or not this app server is shutting down
var shuttingDown = false;

/*!
 * When the system starts shutting down, we want to abort any collections that are happening. As collections will
 * continue until the bucket is empty, we want to ensure it completes within the shutdown grace-time. The only way
 * we can ensure that is to force it to stop after the current batch.
 */
OAE.registerPreShutdownHandler('oae-activity-buckets', null, function(callback) {
    log().info('Enabling shutdown status to abort any current bucket collections as soon as possible');
    shuttingDown = true;
    return callback();
});

/**
 * Get the bucket number for a given string. The string should be a derivative of what you're putting into the
 * buckets. Given the same item, it should return the same string. The same string will always be placed in the
 * same bucket. This property is useful to group items in the same bucket that you wish to deal with at the same
 * time.
 *
 * @param  {String}     str                 The string that will be hashed
 * @param  {Number}     numberOfBuckets     The maximum number of buckets that can be created
 * @return {Number}                         The bucket number that identifies the given string
 */
var getBucketNumber = module.exports.getBucketNumber = function(str, numberOfBuckets) {
    var sum = crypto.createHash('md5');
    sum.update(str);

    // Slice the last 4 characters of the hex to avoid integer overflow. This will give max 2^16 buckets
    var hex = sum.digest('hex').slice(-4);
    return parseInt(hex, 16) % numberOfBuckets;
};

/**
 * Perform a full collection of all buckets. If any bucket is already locked by another process, it will be skipped. When
 * this process completes and the callback is invoked, it will guarantee that:
 *
 * a) This process was not allowed to start another collection cycle, as there were too many occuring; or
 * b) for every bucket that wasn't locked, it was collected until it was empty.
 *
 * This is most useful for unit tests to ensure that all activities up until a point in time have been aggregated and delivered.
 *
 * @param  {String}     type                        A unique string that identifies which type of bucket should be collected
 * @param  {Number}     numberOfBuckets             The number of buckets that should be collected
 * @param  {Number}     maxConcurrentCollections    The maximum number of concurrent collections that can occur for the given type
 * @param  {Number}     collectionExpiry            The duration for which a bucket is locked. Ensure that this is sufficiently long for your `collector` to run
 * @param  {Function}   collector                   The function that should be invoked when a bucket can be collected
 * @param  {Object}     collector.err               Any error that occurred during the collection, if any
 * @param  {Boolean}    collector.finished          Indicates that the bucket is drained or has been skipped in which case it should not be retried either
 * @param  {Function}   [callback]                  Standard callback function
 * @param  {Object}     [callback.err]              An error that occurred, if any
 */
var collectAllBuckets = module.exports.collectAllBuckets = function(type, numberOfBuckets, maxConcurrentCollections, collectionExpiry, collector, callback) {
    callback = callback || function(err) {
        if (err) {
            log().error({'err': err}, 'Error collecting buckets');
        }
    };

    bucketsInfo[type] = bucketsInfo[type] || {
        'numberOfBuckets': numberOfBuckets,
        'maxConcurrentCollections': maxConcurrentCollections,
        'currentConcurrentCollectionCount': 0,
        'collectionExpiry': collectionExpiry,
        'collector': collector,
        'telemetry': TelemetryAPI.telemetry(util.format('bucket-%s', type))
    };

    // Ensure we don't surpass the maximum number of concurrent collections
    if (bucketsInfo[type].currentConcurrentCollectionCount >= bucketsInfo[type].maxConcurrentCollections) {
        log().trace({'type': type}, 'Aborting collection due to max concurrent collections count reached');
        return callback();
    }
    bucketsInfo[type].currentConcurrentCollectionCount++;

    // Fill all the possible bucket numbers to collect
    var bucketNumbers = [];
    for (var i = 0; i < bucketsInfo[type].numberOfBuckets; i++) {
        bucketNumbers.push(i);
    }

    log().trace({'type': type}, 'Beginning collection of %s buckets', bucketNumbers.length);

    // Perform a collection cycle on the bucket numbers
    _collectBuckets(type, bucketNumbers, function(err) {
        log().trace({'type': type}, 'Completed collection cycle');

        // Mark that this collection cycle has completed, whether or not there was an error
        bucketsInfo[type].currentConcurrentCollectionCount--;
        return callback(err);
    });
};

/**
 * Collects the given array of bucket numbers until they are empty, or "stolen". This process will skip over buckets that are
 * in the process of being collected. Therefore, if all buckets in the array are currently undergoing collection, this will not
 * actually perform any collections. This process will only attempt to collect one bucket at a time in order given in the array.
 *
 * @param  {String}     type            A unique string that identifies which type of bucket should be collected
 * @param  {Number[]}   bucketNumbers   The buckets that should be collected by this cycle
 * @param  {Function}   callback        Standard callback function
 * @param  {Object}     callback.err    An error that occurred, if any
 * @api private
 */
var _collectBuckets = function(type, bucketNumbers, callback, _errs) {
    _errs = _errs || [];
    if (_.isEmpty(bucketNumbers)) {
        // Return the first error, if there was any
        return callback(_errs[0]);
    }

    var bucketNumber = bucketNumbers.pop();
    _collectBucket(type, bucketNumber, function(err) {
        if (err) {
            log().warn({'err': err, 'bucketNumber': bucketNumber, 'type': type}, 'Error collecting aggregate bucket');
            bucketsInfo[type].telemetry.incr('collection.error.count');
            _errs.push(err);
        }

        return _collectBuckets(type, bucketNumbers, callback, _errs);
    });
};

/**
 * Collect the provided bucket number until it is empty (or "stolen"). If the bucket is already being collected, this will
 * effectively do nothing.
 *
 * @param  {String}    type                A unique string that identifies which type of bucket should be collected
 * @param  {Number}    bucketNumber        The number of the bucket to collect
 * @param  {Function}  callback            Standard callback function
 * @param  {Object}    callback.err        An error that occurred, if any
 * @api private
 */
var _collectBucket = function(type, bucketNumber, callback) {
    if (shuttingDown) {
        log().info({'type': type}, 'Aborting bucket collection of bucket %s as shutdown is in progress', bucketNumber);
        return callback();
    }

    var bucketInfo = bucketsInfo[type];

    log().trace('Attempting collection of bucket number %s %s', type, bucketNumber);
    // Try and acquire a lock on the bucket to collect the next batch
    var lockKey = _getLockKey(type, bucketNumber);
    Locking.acquire(lockKey, bucketInfo.collectionExpiry, function(err, lockId) {
        if (err) {
            return callback(err);
        } else if (!lockId) {
            // We could not acquire a lock, someone else came around and managed to snag the bucket
            return callback();
        }

        log().trace({'lockId': lockId, 'type': type}, 'Acquired a lock on bucket number %s', bucketNumber);

        // We acquired the lock, perform a collection iteration
        bucketInfo.collector(bucketNumber, function(collectionErr, finished) {

            // We want to ensure we release the bucket, whether we received an error or not
            Locking.release(lockKey, lockId, function(releaseErr, hadLock) {
                if (collectionErr) {
                    return callback(collectionErr);
                } else if (releaseErr) {
                    log().warn({'err': releaseErr, 'type': type}, 'An unexpected error occurred while releasing the lock from bucket number %s', bucketNumber);

                    // If there was an error releasing the lock, worst case scenario would be that the lock eventually expires
                    // and a cluster node picks it up soon after that and continues processing
                    return callback(releaseErr);
                }

                log().trace({'lockId': lockId, 'type': type}, 'Successfully released lock for bucket number %s', bucketNumber);

                if (!hadLock) {
                    // This means that the lock expired before we finished collecting, which likely means the lock expiry
                    // is not configured high enough for the collection batch size. Send an error, because it will almost
                    // certainly end up in a noticeable degradation of user experience
                    log().error({
                        'type': type,
                        'collectionExpiry': bucketInfo.collectionExpiry
                    }, 'The bucket lock expired before we finished collecting a bucket. This probably means that it takes ' +
                       'longer than the "collectionExpiry" number of seconds for the collector to run. Consider either ' +
                       'increasing "collectionExpiry" or decreasing the amount of items one invocation of the collector handles');
                }

                if (finished) {
                    // The bucket is now dealt with, return to the caller
                    return callback();
                }

                // The bucket isn't dealt with, try another collection iteration
                return _collectBucket(type, bucketNumber, callback);
            });
        });
    });
};

/**
 * Get the lock key for the given bucket number and type
 *
 * @param  {String}     type            A unique string that identifies which type of bucket should be collected
 * @param  {Number}     bucketNumber    The bucket number for which to create the lock key
 * @return {String}                     The key that can be used to lock the bucket with the given number
 * @api private
 */
var _getLockKey = function(type, bucketNumber) {
    return util.format('oae-activity:%s:lock-%s', type, bucketNumber);
};
