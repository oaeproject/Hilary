/*!
 * Copyright 2013 Apereo Foundation (AF) Licensed under the
 * Educational Community License, Version 2.0 (the "License"); you may
 * not use this file except in compliance with the License. You may
 * obtain a copy of the License at
 *
 *     http://opensource.org/licenses/ECL-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an "AS IS"
 * BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 * or implied. See the License for the specific language governing
 * permissions and limitations under the License.
 */

var awssum = require('awssum');
var fs = require('fs');
var Path = require('path');
var ShortId = require('shortid');
var util = require('util');

var Cassandra = require('oae-util/lib/cassandra');
var Config = require('oae-config').config('oae-content');
var IO = require('oae-util/lib/io');
var log = require('oae-logger').logger('amazon-storage');
var Revision = require('oae-content/lib/model').Revision;
var TempFile = require('oae-util/lib/tempfile');
var Validator = require('oae-util/lib/validator').Validator;

var BackendUtil = require('./util');



var amazon = awssum.load('amazon/amazon');
var S3 = awssum.load('amazon/s3').S3;

//////////////////////
// Storage methods. //
//////////////////////

/**
 * @borrows Interface.store as Amazons3.store
 */
var store = module.exports.store = function(ctx, file, options, callback) {
    // Generate the uri for this file.
    // We can use this uri later to retrieve it.
    var uri = BackendUtil.generateUri(file, options);

    log().trace('Uploading %s to S3.', uri);

    var stream = fs.createReadStream(file.path);
    stream.once('error', function(err){
        IO.destroyStream(stream);
        log().error({'err': err}, 'Could not upload %s to S3', uri);
        callback({'code': 500, 'msg': err});
    });

    options = {
        'BucketName': _getBucketName(ctx),
        'ObjectName': uri,
        'ContentLength': file.size,
        'Body':  stream
    };

    // Uploads a file to S3.
    // See:
    //  * awssum: http://awssum.io/amazon/s3/put-object.html
    //  * Amazon S3 doc: http://docs.amazonwebservices.com/AmazonS3/latest/API/RESTObjectPUT.html
    _getClient(ctx).PutObject(options, function(err, data) {
        // Remove the file on disk.
        fs.unlink(file.path, function(unlinkError) {
            if (unlinkError) {
                log().warn({'err': unlinkError}, 'Could not remove the temporary file.');
                // We ignore the unlink error, as the file might've actually ended up on S3.
            }

            // Deal with the amazon response.
            if (err) {
                log().error({'err': err}, 'Could not upload to S3.');
                return callback(err);
            }
            callback(null, 'amazons3:' + uri);
        });
    });
};

/**
 * @borrows Interface.get as Amazons3.get
 */
var get = module.exports.get = function(ctx, uri, callback) {
    // Download it to a temp folder.
    var uriObj = BackendUtil.splitUri(uri);

    var filename = Path.basename(uriObj.location);
    var tmp = TempFile.createTempFile({'suffix': filename});
    var writeStream = fs.createWriteStream(tmp.path);

    writeStream.once('error', function(err){
        IO.destroyStream(writeStream);
        log().error({'err': err}, 'Could not save %s to disk', uri);
        callback({'code': 500, 'msg': err});
    });

    log().trace('Downloading %s from S3.', uriObj.location);

    var options = {
        'BucketName': _getBucketName(ctx),
        'ObjectName': uriObj.location
    };

    // Download an "object"(=file) to a temporary folder.
    // See:
    //  * Awssum doc: http://awssum.io/amazon/s3/get-object.html
    //  * Amazon S3 doc: http://docs.amazonwebservices.com/AmazonS3/latest/API/RESTObjectGET.html
    // TODO: Replace with upcoming streaming download
    _getClient(ctx).GetObject(options, function(err, data) {
        if (err) {
            IO.destroyStream(writeStream);
            log().error({'err': err}, 'Failed to download %s from S3.', path);
            return callback({'code': 500, 'msg': err});
        }

        writeStream.on('close', function() {
            tmp.size = data.Headers['content-length'];
            return callback(null, tmp);
        });

        // Pump the data to disk.
        writeStream.end(data.Body);
    });
};

/**
 * @borrows Interface.remove as Amazons3.remove
 */
var remove = module.exports.remove = function(ctx, uri, callback) {
    var uriObj = BackendUtil.splitUri(uri);
    var options = {
        'BucketName': _getBucketName(ctx),
        'ObjectName': uriObj.location
    };

    log().trace('Removing %s from S3.', uriObj.location);

    // Delete it from Amazon S3
    _getClient(ctx).DeleteObject(options, function(err, data) {
        if (err) {
            log().error({'err': err}, 'Error removing %s', uriObj.location);
            return callback({'code': 500, 'msg': 'Unable to remove the file: ' + err});
        }
        callback(null);
    });
};

/**
 * @borrows Interface.getDownloadLink as Amazons3.getDownloadLink
 */
var getDownloadLink = module.exports.getDownloadLink = function(ctx, uri) {
    // We create a signed URL that allows the user to retrieve a file directly from S3.
    // This URL is valid for 5 minutes and can only be used once.
    // This involves adding a Signature parameter that signs a string with:
    //  * the HTTP method (GET)
    //  * an Expires request parameter in seconds since epoch.
    //  * our public key.

    // Date.now returns the milliseconds since epoch, so divide/round it by a thousand.
    var expires = Math.round((Date.now() + 5*60000) / 1000);

    // Sign the URL.
    var s3 = _getClient(ctx);
    uri = _getBucketName(ctx) + '/' + BackendUtil.splitUri(uri).location;
    var url = 'https://s3.amazonaws.com/' + uri;
    url += '?AWSAccessKeyId=' + s3.accessKeyId();
    url += '&Signature=' + encodeURIComponent(s3.signature('GET\n\n\n' + expires + '\n/' + uri));
    url += '&Expires=' + expires;
    return {'code': 302, 'url': url};
};

/**
 * Returns the bucket we'll be using for storing files in.
 * @param  {Context}    ctx     The current execution context.
 * @return {String}             The bucket name
 */
var _getBucketName = function(ctx) {
    return Config.getValue(ctx.tenant().alias, 'storage', 'amazons3-bucket');
};

/**
 * Gets a client that can connect to S3 and is configured via the admin interface.
 * @param  {Context}    ctx     The current execution context.
 * @return {S3}                 An S3 client.
 */
var _getClient = function(ctx) {

    var accessKey = Config.getValue(ctx.tenant().alias, 'storage', 'amazons3-access-key');
    var secretKey = Config.getValue(ctx.tenant().alias, 'storage', 'amazons3-secret-key');
    var region = Config.getValue(ctx.tenant().alias, 'storage', 'amazons3-region');

    return new S3({
        'accessKeyId': accessKey,
        'secretAccessKey': secretKey,
        'region': region
    });
};
