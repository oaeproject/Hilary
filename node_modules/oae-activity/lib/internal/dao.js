/*!
 * Copyright 2014 Apereo Foundation (AF) Licensed under the
 * Educational Community License, Version 2.0 (the "License"); you may
 * not use this file except in compliance with the License. You may
 * obtain a copy of the License at
 *
 *     http://opensource.org/licenses/ECL-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an "AS IS"
 * BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 * or implied. See the License for the specific language governing
 * permissions and limitations under the License.
 */

var _ = require('underscore');
var crypto = require('crypto');
var ShortId = require('shortid');
var util = require('util');

var Cassandra = require('oae-util/lib/cassandra');
var log = require('oae-logger').logger('oae-activity');
var OaeUtil = require('oae-util/lib/util');

var ActivityConstants = require('oae-activity/lib/constants').ActivityConstants;
var ActivitySystemConfig = require('./config');
var ActivityUtil = require('oae-activity/lib/util');

// The redis client that will be used for storing / fetch aggregate entities
var redisClient = null;

/**
 * Initialize the activity DAO.
 *
 * @param  {RedisClient}    redisClient     The redis client to use for aggregation
 */
var init = module.exports.init = function(_redisClient) {
    redisClient = _redisClient;
};

/**
 * Get a list of activities from the specified activity stream.
 *
 * @param  {String}         activityStreamId        The ID of the activity stream. ex: `u:cam:abc123#activity`
 * @param  {Number|String}  [start]                 Number of millis since the epoc (stringified or number version) from which to start returning activities. Only activities older than this timestamp will be returned. By default, will start from the newest.
 * @param  {Number}         [limit]                 The number of activities to return. Default: 25
 * @param  {Function}       callback                Invoked when the process completes
 * @param  {Object}         callback.err            An error that occurred, if any
 * @param  {Activity[]}     callback.activities     The list of activities
 * @param  {String}         callback.nextToken      The value to provide in the `start` parameter to get the next set of results
 */
var getActivities = module.exports.getActivities = function(activityStreamId, start, limit, callback) {
    limit = OaeUtil.getNumberParam(limit, 25);

    // Selecting with consistency ONE as having great consistency is not critical for activities
    Cassandra.runPagedColumnQuery('ActivityStreams', 'activityStreamId', activityStreamId, start, limit, {'reversed': true, 'consistency': 'ONE'}, function(err, columns, nextToken) {
        if (err) {
            return callback(err);
        }

        var activities = _columnsToActivities(columns);

        /*
         * The following block of code is intended for migrating from 3.0.0 to 4.0.0 (Push)
         * The `activityStreamId` for "activity" activity streams is/was of the form:
         *   -  4.0.0:   `u:cam:abc123#activity`   or    `g:cam:abc123#activity`
         *   -  3.0.0:   `u:cam:abc123`            or    `g:cam:abc123`
         *
         * If we detect that a user activity stream is being requested under the following circumstances,
         * we will try the old value as the `activityStreamId`.
         */
        
        // We only need to check with another activityStreamId if the "activity" stream is being requested. Notifications are unchanged
        var parsedActivityStreamId = ActivityUtil.parseActivityStreamId(activityStreamId);
        var isActivityStream = (parsedActivityStreamId.streamType === 'activity');
        if (!isActivityStream) {
            return callback(null, activities, nextToken);
        }

        // If we found the requested amount of activities we can return early
        if (activities.length === limit) {
            return callback(null, activities, nextToken);
        }

        // Otherwise we'll need to check the old value
        var oldActivityStreamLimit = limit - activities.length;
        Cassandra.runPagedColumnQuery('ActivityStreams', 'activityStreamId', parsedActivityStreamId.resourceId, start, oldActivityStreamLimit, {'reversed': true, 'consistency': 'ONE'}, function(err, columns, nextToken) {
            if (err) {
                return callback(err);
            }

            activities = activities.concat(_columnsToActivities(columns));
            return callback(null, activities, nextToken);
        });
    });
};

/**
 * Deliver the given routed activities to their specified routes. The routed activities should be given in the format:
 *
 * ```
 * {
 *     '<route id 0>': {
 *         '<activity id 0>': {Activity},
 *         '<activity id 1>': {Activity},
 *         ...
 *     },
 *     '<route id 1>': {
 *         ...
 *     },
 *     ...
 * }
 * ```
 *
 * @param  {Object}    routedActivities    An object keyed by the route id (a.k.a., activity stream id), whose value is an object of activities to be delivered, keyed by their activity id.
 * @param  {Function}  callback            Invoked when the activities have been delivered
 * @param  {Object}    callback.err        An error that occurred, if any
 */
var deliverActivities = module.exports.deliverActivities = function(routedActivities, callback) {
    callback = callback || function(err) {
        if (err) {
            log().error({'err': err}, 'Error delivering routed activities.');
        }
    };

    var queries = [];
    _.each(routedActivities, function(activities, route) {
        var query = Cassandra.constructUpsertCQL('ActivityStreams', 'activityStreamId', route, activities, null, ActivitySystemConfig.getConfig().activityTtl);
        if (query) {
            queries.push(query);
        } else {
            log().warn({'route': route, 'activities': activities}, 'Failed to create a query while delivering activities. Skipping');
        }
    });

    // Saving activities with consistency ONE because consistency is not critical for activities
    Cassandra.runBatchQuery(queries, 'ONE', callback);
};

/**
 * Delete the specified activities from specific routes.
 *
 * @param  {Object}    routeActivityIds    An object keyed by route, whose value is an array of string activityIds that should be deleted from the route
 * @param  {Function}  callback            Invoked when the activities have been deleted
 * @param  {Object}    callback.err        An error that occurred, if any
 */
var deleteActivities = module.exports.deleteActivities = function(routeActivityIds, callback) {
    var routes = _.keys(routeActivityIds);
    if (routes.length === 0) {
        return callback();
    }

    var queries = [];
    routes.forEach(function(route) {
        var activityIds = routeActivityIds[route];
        if (activityIds.length === 0) {
            return;
        }

        var placeholders = [];
        var params = [];
        activityIds.forEach(function(activityId) {
            placeholders.push('?');
            params.push(activityId);
        });
        params.push(route);

        queries.push({
            'query': 'DELETE ' + placeholders.join(', ') + ' FROM ActivityStreams WHERE activityStreamId = ?',
            'parameters': params
        });
    });

    Cassandra.runBatchQuery(queries, 'ONE', callback);
};

/**
 * Save the given routed activities to the specified queue buckets. A routed activity is essentially an Activity object that
 * is stored along with the route to which it should be delivered:
 *
 * `{ 'route': 'u:oae:mrvisser', 'activity': { <Activity Object> }}`
 *
 * @param  {Object[][]}    activityBuckets     An array whose index represents the bucket number, and whose value represents the array of routed activities to queue into the bucket.
 * @param  {Function}      callback            Invoked when the routed activities have been queued for processing
 * @param  {Object}        callback.err        An error that occurred, if any
 */
var saveQueuedActivities = module.exports.saveQueuedActivities = function(activityBuckets, callback) {
    if (activityBuckets.length === 0) {
        return callback();
    }

    log().trace({'activityBuckets': activityBuckets}, 'Saving queued activities.');

    var now = Date.now();
    var queries = [];

    // We will batch together one redis update command per bucket that needs to be updated
    var multi = redisClient.multi();

    _.each(activityBuckets, function(activityBucket, bucketNumber) {
        if (!activityBucket || !activityBucket.length) {
            return;
        }

        // We use a Redis sorted list ("zadd") to stored bucketed queued activities so that we can always collect the oldest first
        // Arguments to zadd start with the key, then each arguments after are ordered pairs of <rank>, <value>. The "rank" specifies
        // the order in which values will be sorted, from lowest to highest.

        // The bucket cache-key as the first argument
        var zaddArgs = [_createBucketCacheKey(bucketNumber)];
        _.each(activityBucket, function(routedActivity) {
            // Append the ordered pair of <rank>, <value> for this routed activity
            zaddArgs.push(routedActivity.activity.published);
            zaddArgs.push(JSON.stringify(routedActivity));
        });

        // Append this bucket zadd command to the batch
        multi.zadd(zaddArgs);
    });

    // Finally execute the zadd commands to append the values to bucket's sorted lists
    multi.exec(callback);
};

/**
 * Get the queued activities from the given bucket number for processing.
 *
 * @param  {Number}    bucketNumber                The bucket from which to fetch the queued activities
 * @param  {Number}    limit                       How many routed activities to fetch from the queue
 * @param  {Function}  callback                    Invoked when the process completes
 * @param  {Object}    callback.err                An error that occurred, if any
 * @param  {Object}    callback.routedActivities   The routed activities that were queued in the bucket. The key is the internally created id of the entry (which can be used to later delete the entry), and value is a routed activity, as documented in #saveQueuedActivities
 */
var getQueuedActivities = module.exports.getQueuedActivities = function(bucketNumber, limit, callback) {
    limit = OaeUtil.getNumberParam(limit, ActivitySystemConfig.getConfig().collectionBatchSize);

    // Get the first `limit` routed activities from the bucket. Since they are stored in a sorted list in Redis, we use the
    // "zrange" command. The "z" prefix to the command indicates that it is a sorted-list operation.
    redisClient.zrange(_createBucketCacheKey(bucketNumber), 0, limit, function(err, routedActivities) {
        if (err) {
            return callback(err);
        }

        // The Redis result is each value on a new line, in order of "rank" in the sorted-list. Iterate over those and parse the values in order.
        var queuedActivities = {};
        _.each(routedActivities, function(routedActivity) {
            try {
                // Routed activities are stored as stringified JSON, so we parse them back to objects
                routedActivity = JSON.parse(routedActivity);
            } catch (err) {
                log().warn({'err': err, 'routedActivity': routedActivity}, 'Error trying to parse stored routed activity.');
                return;
            }

            queuedActivities[_createRoutedActivityKey(routedActivity)] = routedActivity;
        });

        log().trace({'queuedActivities': queuedActivities}, 'Fetched queued activities.');

        return callback(null, queuedActivities);
    });
};

/**
 * Delete queued activities from a bucket.
 *
 * @param  {Number}    bucketNumber        The number of the bucket from which to delete the queued activities
 * @param  {Number}    numberToDelete      The number of activities (starting from the earliest) from the earliest set of activities to delete from the bucket
 * @param  {Function}  callback            Invoked when the routed activities have been deleted
 * @param  {Object}    callback.err        An error that occurred, if any
 */
var deleteQueuedActivities = module.exports.deleteQueuedActivities = function(bucketNumber, numberToDelete, callback) {
    if (!numberToDelete) {
        return callback();
    }

    log().trace({'bucketNumber': bucketNumber, 'numberToDelete': numberToDelete}, 'Deleting queued activities.');

    // Use "zremrangebyrank", which will delete the first "numberToDelete" items in the sorted-list, ordered by their "rank"
    redisClient.zremrangebyrank(_createBucketCacheKey(bucketNumber), 0, numberToDelete - 1, callback);
};

/**
 * Get the aggregation status for the aggregates identified by the given aggregate keys. Can be used to determine if any aggregates
 * are currently aggregating, expired, the id of the last activity delivery, etc... An example status looks like:
 *
 * ```javascript
 *  {
 *      'lastActivity': 'PTeijwe',      // The ID of the last activity that was delivered for the aggregate
 *      'lastUpdated': 123456789,       // The timestamp (millis since epoch) that the last activity matched this aggregate
 *      'lastCollected': 123456780,     // The timestamp (millis since epoch) since the aggregate was last collected
 *      'created': 123448430            // The timestamp (millis since epoch) since the aggregate was created
 *  }
 * ```
 *
 * @param  {String[]}  aggregateKeys               The aggregate keys for which to fetch the aggregate status
 * @param  {Function}  callback                    Invoked when the process completes
 * @param  {Object}    callbcak.err                An error that occurred, if any
 * @param  {Object}    callback.aggregateStatus    An object, keyed by the aggregate key, whose value is the status of the aggregate
 */
var getAggregateStatus = module.exports.getAggregateStatus = function(aggregateKeys, callback) {
    if (aggregateKeys.length === 0) {
        return callback(null, {});
    }

    // Fetch each aggregate status by key. This uses a Redis multi-get ("mget"), whose arguments must be an array of all the keys to fetch
    var mgetArgs = [];
    _.each(aggregateKeys, function(aggregateKey) {
        mgetArgs.push(_createAggregateStatusCacheKey(aggregateKey));
    });

    // Gather the redis keys for the aggregate statii
    redisClient.mget(mgetArgs, function(err, results) {
        if (err) {
            return callback(err);
        }

        // The result is each aggregate status separated by a new line, ordered the same as the keys were in the args. Therefore
        // we iterate over those one-by-one and match the aggregate status result with the aggregate key by index.
        var aggregateStatus = {};
        for (var i = 0; i < results.length; i++) {

            // Match the aggregate status result with the aggregate key by index.
            var result = results[i];
            var aggregateKey = aggregateKeys[i];

            if (result) {
                try {
                    // The aggregate status was stored as stringified JSON, so parse it.
                    result = JSON.parse(result);
                    aggregateStatus[aggregateKey] = result;
                } catch (ex) {
                    log().warn({'err': ex}, 'Found invalid aggregate status entry. Skipping.');
                }
            }
        }

        return callback(null, aggregateStatus);
    });
};

/**
 * Update a set of aggregate status with a new status.
 *
 * @param  {Object}    statusUpdates   An object keyed by aggregate key whose values are the new status information for the aggregate
 * @param  {Function}  callback        Invoked when the aggregates have been updated
 * @param  {Object}    callback.err    An error that occurred, if any
 */
var updateAggregateStatus = module.exports.updateAggregateStatus = function(statusUpdates, callback) {
    var aggregateKeys = _.keys(statusUpdates);
    if (aggregateKeys.length === 0) {
        return callback();
    }

    // We will have to execute multiple redis update commands, so we use a multi object which will handle this.
    var multi = redisClient.multi();

    // We use a redis multi-set ("mset") command to set all the aggregate status updates. The arguments take and array of ordered pairs of "key1 value1 key2 value2", which will be stored in msetArgs
    var msetArgs = [];

    // We will need to update the expiry of each aggregate status that is touched, this will hold the keys of the aggregate statuses whose ttl/expiry should be udpated
    var keysToExpire = [];

    _.each(statusUpdates, function(status, aggregateKey) {
        var statusKey = _createAggregateStatusCacheKey(aggregateKey);

        // Push the key, value pair into the mset arguments and collect the key as it will need to have its ttl updated
        msetArgs.push(statusKey, JSON.stringify(status));
        keysToExpire.push(statusKey);
    });

    // Append the mset command to the multi-command
    multi.mset(msetArgs);

    // For each key to expire, append the Redis 'expire' command to the multi-command
    _.each(keysToExpire, function(key) {
        multi.expire(key, ActivitySystemConfig.getConfig().aggregateIdleExpiry);
    });

    // Finally execute all the appended commands
    multi.exec(callback);
};

/**
 * Delete all the aggregation data associated to the given aggregate keys. This includes both the status and the aggregated entities.
 *
 * @param  {String[]}  aggregateKeys   The aggregate keys whose history to delete
 * @param  {Function}  callback        Invoked when the aggregation history has been deleted
 * @param  {Object}    callback.err    An error that occurred, if any
 */
var deleteAggregates = module.exports.deleteAggregates = function(aggregateKeys, callback) {
    if (aggregateKeys.length === 0) {
        return callback();
    }

    // The redis delete ("del") command takes an array of keys to delete. We represent this as an array of cache keys that must be deleted
    var delArgs = [];
    _.each(aggregateKeys, function(aggregateKey) {
        // Delete the status and aggregated entities for each aggregate
        delArgs.push(_createAggregateStatusCacheKey(aggregateKey));
        delArgs.push(_createAggregateEntityCacheKey(aggregateKey, 'actors'));
        delArgs.push(_createAggregateEntityCacheKey(aggregateKey, 'objects'));
        delArgs.push(_createAggregateEntityCacheKey(aggregateKey, 'targets'));
    });

    // Delete all the collected cache keys
    redisClient.del(delArgs, callback);
};

/**
 * Get all the entities that have been aggregated for the aggregate key. The resulting object holds all the actors, objects and targets
 * that have been aggregated for the aggregate key. This is an example of how the object is represented:
 *
 * ```javascript
 *  {
 *      '<aggregateKey0>': {
 *          'actors': {
 *              '<entityKey0>': { <Entity> },
 *              '<entityKey1>': { <Entity> }
 *          },
 *          'objects': {
 *              '<entityKey2>': { <Entity> },
 *              '<entityKey3>': { <Entity> }
 *          },
 *          'targets': {
 *              '<entityKey4>': { <Entity> }
 *          }
 *      },
 *      '<aggregateKey1>': { ... },
 *      ...
 *  }
 * ```
 *
 * @param  {String[]}  aggregateKeys               The aggregate keys for which to fetch the aggregated entities
 * @param  {Function}  callback                    Invoked when the process completes
 * @param  {Object}    callback.err                An error that occurred, if any
 * @param  {Object}    callback.aggregatedEntities An object holding the entities that have been aggregated for the entities. See summary for more information
 */
var getAggregatedEntities = module.exports.getAggregatedEntities = function(aggregateKeys, callback) {
    if (aggregateKeys.length === 0) {
        return callback(null, {});
    }

    /*!
     * Each aggregate key has actors, objects and targets associated to it, and each of those are stored as separate cache entries. For
     * example:
     *
     * ```
     *  "aggregateKey0:actors": {
     *      "<entityKey0>": "<entityIdentity0>",
     *      "<entityKey1>": "<entityIdentity1>"
     *  }
     *
     *  "aggregateKey0:objects": {
     *      "<entityKey2>": "<entityIdentity2>"
     *  }
     *
     *  "aggregateKey0:targets": {
     *      "<entityKey3>": "<entityIdentity3>"
     *  }
     * ```
     *
     * The "aggregateKey0:actors" value is a cache key and its value is a Redis "hash". The entity keys in the hashes represent all
     * entities that have been aggregated for the associated aggregate key + entity type. The value of the hash is a cache key that
     * can be used to fetch the entity that represents the entity keyed by the entity key.
     *
     * To get all the aggregated entities for an aggregate key, we have to use a redis multi command and parse the result. Here is
     * an example:
     *
     * ```
     *  multi
     *  hgetall "aggregateKey0:actors"
     *  hgetall "aggregateKey0:objects"
     *  hgetall "aggregateKey0:targets"
     *  exec
     * ```
     *
     * This fetches all the actors, objects and targets. The result of this will be an array of the results of each command, separated by a new line:
     *
     * ```
     *  [
     *      {
     *          "<entityKey0>": "<entityIdentity0>",
     *          "<entityKey1>": "<entityIdentity1>"
     *      },
     *      { "<entityKey2>": "<entityIdentity2>" },
     *      { "<entityKey3>": "<entityIdentity3>" }
     *  ]
     * ```
     *
     * To construct the result of the query, a second command is needed to fetch the entities that are represented by the entity identities. That is
     * performed using a Redis multi-get ("mget"), by `_fetchEntitiesByIdentities`.
     */

     // Collect all the hgetall commands for the actor, object and targets of each aggregate key and execute it
    var multiGetAggregateEntities = redisClient.multi();
    _.each(aggregateKeys, function(aggregateKey) {
        multiGetAggregateEntities.hgetall(_createAggregateEntityCacheKey(aggregateKey, 'actors'));
        multiGetAggregateEntities.hgetall(_createAggregateEntityCacheKey(aggregateKey, 'objects'));
        multiGetAggregateEntities.hgetall(_createAggregateEntityCacheKey(aggregateKey, 'targets'));
    });

    // First fetch the references to the aggregated entity objects
    multiGetAggregateEntities.exec(function(err, results) {
        if (err) {
            return callback(err);
        }

        log().trace({'results': results}, 'Multi fetch identities result.');

        // Collect all the actual identities that are stored in this result. We will use those to fetch the
        // actual entity contents
        var entityIdentities = {};
        _.each(results, function(result) {
            if (result) {
                _.each(result, function(entityIdentity, entityKey) {
                    if (entityIdentity) {
                        entityIdentities[entityIdentity] = true;
                    }
                });
            }
        });

        // Get the full entity objects using the identities
        _fetchEntitiesByIdentities(_.keys(entityIdentities), function(err, entitiesByIdentity) {
            if (err) {
                return callback(err);
            }

            var aggregateEntities = {};
            _.each(results, function(result, i) {
                if (result) {

                    // Every 3 results is a new aggregate key (one for actor, object and target)
                    var aggregateKeyIndex = Math.floor(i / 3);

                    // Within each set of 3 results, the first is the actor, the second is object and the 3rd is the target. Use % to select the right one
                    var entityIndex = i % 3;

                    var aggregateKey = aggregateKeys[aggregateKeyIndex];
                    var entityType = null;
                    if (entityIndex === 0) {
                        entityType = 'actors';
                    } else if (entityIndex === 1) {
                        entityType = 'objects';
                    } else if (entityIndex === 2) {
                        entityType = 'targets';
                    }

                    // Seed the aggregate entities for the aggregate key
                    aggregateEntities[aggregateKey] = aggregateEntities[aggregateKey] || {
                        'actors': {},
                        'objects': {},
                        'targets': {}
                    };

                    log().trace({'aggregate': result}, 'Iterating aggregated entity identities to map to full entities');

                    _.each(result, function(identity, entityKey) {
                        // Grab the entity from the identity map that was fetched
                        aggregateEntities[aggregateKey][entityType][entityKey] = entitiesByIdentity[identity];
                    });
                }
            });

            log().trace({'aggregateEntities': aggregateEntities}, 'Fetched aggregated entities.');

            return callback(null, aggregateEntities);
        });
    });
};

/**
 * Fetch the entity objects that are referenced by the given array of identities.
 *
 * @param  {String[]}   entityIdentities    The identities that reference the entities to fetch
 * @param  {Function}   callback            Invoked when the process completes
 * @param  {Object}     callback.err        An error that occurred, if any
 * @api private
 */
var _fetchEntitiesByIdentities = function(entityIdentities, callback) {
    if (entityIdentities.length === 0) {
        return callback(null, {});
    }

    var entitiesByIdentity = {};

    // Convert the entity identities into their associated cache keys
    var entityIdentityCacheKeys = _.map(entityIdentities, function(entityIdentity) {
        return _createEntityIdentityCacheKey(entityIdentity);
    });

    redisClient.mget(entityIdentityCacheKeys, function(err, results) {
        if (err) {
            return callback(err);
        }

        // Parse each entity from storage as they are stored as stringified JSON
        _.each(results, function(entityStr, i) {
            if (entityStr) {
                try {
                    entitiesByIdentity[entityIdentities[i]] = JSON.parse(entityStr);
                } catch (ex) {
                    log().warn({'entityStr': entityStr}, 'Failed to parse aggregated activity entity from redis. Skipping.');
                }
            }
        });

        log().trace({
            'entityIdentities': entityIdentities,
            'entitiesByIdentity': entitiesByIdentity
        }, 'Fetched entities by identity from redis.');

        return callback(null, entitiesByIdentity);
    });
};

/**
 * Save the aggregated entities for the specified aggregates.
 *
 * @param  {Object}    aggregates      An object keyed by aggregateKey whose value is an aggregate object containing the `actors`, `objects` and `targets` entities to add to the aggregated entities
 * @param  {Function}  callback        Invoked when the aggregates have been saved
 * @param  {Object}    callback.err    An error that occurred, if any
 */
var saveAggregatedEntities = module.exports.saveAggregatedEntities = function(aggregates, callback) {
    if (_.isEmpty(aggregates)) {
        return callback();
    }

    log().trace({'aggregates': aggregates}, 'Saving aggregate entities.');

    /*!
     * For details on how these are persisted in redis, see the large summary comment within #getAggregatedEntities
     */

    var multi = redisClient.multi();
    _.each(aggregates, function(aggregate, aggregateKey) {
        var hmsetActorArgs = [];
        var hmsetObjectArgs = [];
        var hmsetTargetArgs = [];

        var aggregateActorsKey = _createAggregateEntityCacheKey(aggregateKey, 'actors');
        var aggregateObjectsKey = _createAggregateEntityCacheKey(aggregateKey, 'objects');
        var aggregateTargetsKey = _createAggregateEntityCacheKey(aggregateKey, 'targets');

        // Stores a mapping of identity -> full entity. These are stored by reference to avoid many duplicates consuming memory
        var entitiesByIdentity = {};

        // To set all the entity hash values, we use the Redis Hash Multi-set ("hmset") command. The args for each command starts with
        // the cache key, followed by key-value pairs for the hash key and the hash value.
        if (!_.isEmpty(aggregate.actors)) {
            // First push the cache key
            hmsetActorArgs.push(aggregateActorsKey);
            _.each(aggregate.actors, function(actor, actorKey) {
                var identity = _createEntityIdentity(actor, actorKey);

                // Then push the entity reference (its identity)
                hmsetActorArgs.push(actorKey, identity);

                // Record the entity by its identity, as we will need to store it separately
                entitiesByIdentity[identity] = actor;
            });
        }

        if (!_.isEmpty(aggregate.objects)) {
            // First push the cache key
            hmsetObjectArgs.push(aggregateObjectsKey);
            _.each(aggregate.objects, function(object, objectKey) {
                var identity = _createEntityIdentity(object, objectKey);

                // Then push the entity reference (its identity)
                hmsetObjectArgs.push(objectKey, identity);

                // Record the entity by its identity, as we will need to store it separately
                entitiesByIdentity[identity] = object;
            });
        }

        if (!_.isEmpty(aggregate.targets)) {
            // First push the cache key
            hmsetTargetArgs.push(aggregateTargetsKey);
            _.each(aggregate.targets, function(target, targetKey) {
                var identity = _createEntityIdentity(target, targetKey);

                // Then push the entity reference (its identity)
                hmsetTargetArgs.push(targetKey, identity);

                // Record the entity by its identity, as we will need to store it separately
                entitiesByIdentity[identity] = target;
            });
        }

        log().trace({
            'actorArgs': hmsetActorArgs,
            'objectArgs': hmsetObjectArgs,
            'targetArgs': hmsetTargetArgs
        }, 'Setting hmset arguments for saving queued activities.');

        // Append each set operation to the multi command
        if (hmsetActorArgs.length > 0) {
            multi.hmset(hmsetActorArgs);
        }

        if (hmsetObjectArgs.length > 0) {
            multi.hmset(hmsetObjectArgs);
        }

        if (hmsetTargetArgs.length > 0) {
            multi.hmset(hmsetTargetArgs);
        }

        // Since we've updated this, we reset the expiry so it will be removed after the idle time
        multi.expire(aggregateActorsKey, ActivitySystemConfig.getConfig().aggregateIdleExpiry);
        multi.expire(aggregateObjectsKey, ActivitySystemConfig.getConfig().aggregateIdleExpiry);
        multi.expire(aggregateTargetsKey, ActivitySystemConfig.getConfig().aggregateIdleExpiry);

        // Set the actual entity object values into redis using an mset
        var msetArgs = [];
        var toExpire = [];
        _.each(entitiesByIdentity, function(entity, identity) {
            var identityCacheKey = _createEntityIdentityCacheKey(identity);
            // Redis mset arguments are: key, value, key1, value1, etc...
            msetArgs.push(identityCacheKey, JSON.stringify(entity));

            // We also collect the redis keys that will need to be expired (see below)
            toExpire.push(identityCacheKey);
        });

        log().trace({'msetArgs': msetArgs}, 'Persisting entities in redis by identity.');

        multi.mset(msetArgs);

        // We need to reset the expiry of each identity-entity pair to the aggregatedMaxExpiry to ensure that the entities
        // live as long as any aggregate referencing it needs it for aggregation. This *cannot* be the aggregateIdleExpiry
        // because an aggregate can be updated with a *different* entity, in which case this entity may expire before the
        // aggregate expires, and that would be bad.
        _.each(toExpire, function(identityCacheKey) {
            multi.expire(identityCacheKey, ActivitySystemConfig.getConfig().aggregateMaxExpiry);
        });

    });

    // Finally execute the commands
    multi.exec(callback);
};

/**
 * Create a unique string identifier for an activity that was posted at the given publishing date.
 *
 * @param  {Number}    published   The time (millis since the epoch) that the activity was published.
 * @return {String}                A unique identifier for the activity.
 */
var createActivityId = module.exports.createActivityId = function(published) {
    // An example activity id is: 123456789:PTewoief
    return util.format('%s:%s', published, ShortId.generate());
};


///////////////////
// NOTIFICATIONS //
///////////////////

/**
 * Reset the notifications unread count to 0 in the notifications cache. This *only* updates the cached copy of
 * the count.
 *
 * @param  {String}     userId          The id of the user whose notifications unread count to reset
 * @param  {Function}   callback        Invoked when the process completes
 * @param  {Object}     callback.err    An error that occurred, if any
 */
var clearNotificationsUnreadCount = module.exports.clearNotificationsUnreadCount = function(userId, callback) {
    var cacheKey = _createNotificationCountCacheKey(userId);
    redisClient.del(cacheKey, callback);
};

/**
 * Increment the notifications counts for all the provided users, by the number provided for each user.
 *
 * @param  {Object}     userIdsIncrBy       An object whose key is the userId, and the value is the number by which to increment their notifications unread count
 * @param  {Function}   callback            Invoked when the process completes
 * @param  {Object}     callback.err        An error that occurred, if any
 * @param  {Object}     callback.newCounts  An object whose key is the userId, and the value is the new count value for each user
 */
var incrementNotificationsUnreadCounts = module.exports.incrementNotificationsUnreadCounts = function(userIdsIncrBy, callback) {
    var userIds = _.keys(userIdsIncrBy);
    if (_.keys(userIdsIncrBy).length === 0) {
        return callback(null, {});
    }

    // We use a batch of Redis incrby commands to update each count
    var multi = redisClient.multi();
    _.each(userIds, function(userId) {
        var cacheKey = _createNotificationCountCacheKey(userId);
        multi.incrby(cacheKey, userIdsIncrBy[userId]);
    });

    multi.exec(function(err, results) {
        if (err) {
            return callback(err);
        }

        /*!
         * The result is the new counts for the cache keys, separated by new line:
         *
         *  <userId0>
         *  7
         *  <userId1>
         *  3
         * ...
         */
        var newValues = {};
        _.each(results, function(newValue, i) {
            newValues[userIds[i]] = newValue;
        });

        return callback(null, newValues);
    });
};

/**
 * For an aggregate, create the Cassandra query needed to update the aggregate with the new entities of the specified plural form of the
 * `entityType` (i.e., 'actors', 'objects' or 'targets').
 *
 * @param  {String}     aggregateKey    The unique key of the aggregate
 * @param  {Object}     aggregate       The activity aggregate that holds the entities to save
 * @param  {String}     entityType      The (plural) type of entity to create the query for. One of 'actors', 'objects' or 'targets'
 * @return {Object}                     A query that can be added to a list of batch queries that adds/updates the entities for the given aggregate and entityType
 * @api private
 */
var _getAggregatedEntityQuery = function(aggregateKey, aggregate, entityType) {
    // The key for the aggregated entity row will be an aggregate key (<activityType>#<route>#<actorKey>#<objectKey>#<targetKey>)
    // appended by either '#actors', '#objects' or '#targets', denoting which type of aggregate entity it will be holding
    var key = util.format('%s#%s', aggregateKey, entityType);
    return Cassandra.constructUpsertCQL('ActivityAggregateEntities', 'aggregateKey', key, aggregate[entityType], null, ActivitySystemConfig.getConfig().aggregateMaxExpiry);
};

/**
 * Convert a Cassandra row into an array of activities extracted from its columns.
 *
 * @param  {Column[]}   columns     The Cassandra columns from which to extract the activities
 * @return {Object}                 The activities that were extracted from the rows
 * @api private
 */
var _columnsToActivities = function(columns) {
    var activities = [];
    columns.forEach(function(column) {
        try {
            activities.push(JSON.parse(column.value));
        } catch (err) {
            log().warn({'err': err, 'activityId': column.name, 'value': column.value}, 'Error parsing activity');
        }
    });
    return activities;
};

/**
 * Given an entity, create an identity key that represents its unique contents.
 *
 * @param  {Object}     The persistent entity for which to create an identity
 * @param  {String}     The key of the entity forwhich to create an identity
 */
var _createEntityIdentity = function(entity, entityKey) {
    var md5sum = crypto.createHash('md5');

    // We're simply using `JSON.stringify`, but is not perfect as object properties could technically be in a different
    // order. Assuming most objects are built in the same way this should be fine, however it would be more correct to
    // use a deep-normalized representation by, say, sorting the keys or something.
    md5sum.update(JSON.stringify(entity));
    return util.format('%s:%s', entityKey, md5sum.digest('hex'));
};

/**
 * Get the storage key for an activity bucket.
 *
 * @param  {Number}     bucketNumber    The number of the bucket whose id to create
 * @api private
 */
var _createBucketCacheKey = function(bucketNumber) {
    // Looks like: oae-activity:bucket:0
    return util.format('oae-activity:bucket:%s', bucketNumber);
};

/**
 * Get the storage key for the status of an aggregate key.
 *
 * @param  {String}     aggregateKey    The aggregate key for which to get the status storage key
 * @return {String}                     The storage key for the aggregate's status entity
 * @api private
 */
var _createAggregateStatusCacheKey = function(aggregateKey) {
    // Looks like oae-activity:aggregate:<aggregateKey>:status
    return util.format('oae-activity:aggregate:%s:status', aggregateKey);
};

/**
 * Get the storage key for the aggregated entities of an aggregate.
 *
 * @param  {String}     aggregateKey    The aggregate key for which to get the entity storage key
 * @param  {String}     entityType      The type of entity for which to generate the storage key. One of "actors", "objects", "targets"
 * @return {String}                     The storage key for the aggregate's aggregated entities
 * @api private
 */
var _createAggregateEntityCacheKey = function(aggregateKey, entityType) {
    // Looks like oae-activity:aggregate:<aggregateKey>:actor:entities
    return util.format('oae-activity:aggregate:%s:%s:entities', aggregateKey, entityType);
};

/**
 * Create the storage key for an entity given its identity.
 *
 * @param  {String}     identity    The entity identity with which to create the cache key
 * @return {String}                 The storage key for the entity with the given identity
 * @api private
 */
var _createEntityIdentityCacheKey = function(identity) {
    return util.format('oae-activity:entity:%s', identity);
};

/**
 * Get the key for a routed activity.
 *
 * @param  {Object}     routedActivity  An object with key `route` for the route to which the activity is being routed, and `activity` representing the activity.
 * @return {String}                     The routed activity key
 * @api private
 */
var _createRoutedActivityKey = function(routedActivity) {
    // Looks like <activityId>:u:cam:dfjDFOij
    return util.format('%s:%s', routedActivity.activity[ActivityConstants.properties.OAE_ACTIVITY_ID], routedActivity.route);
};

/**
 * Get the key that holds the unread count for the user with the provided userId
 *
 * @param  {String}     userId  The id of the user
 * @return {String}             The cache key for the counts of the user
 * @api private
 */
var _createNotificationCountCacheKey = function(userId) {
    return util.format('oae-activity:notification-count:%s', userId);
};
